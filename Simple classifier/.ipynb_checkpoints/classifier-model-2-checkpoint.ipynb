{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>investor</th>\n",
       "      <th>commit</th>\n",
       "      <th>deal_size</th>\n",
       "      <th>invite</th>\n",
       "      <th>rating</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>covenants</th>\n",
       "      <th>total_fees</th>\n",
       "      <th>fee_share</th>\n",
       "      <th>prior_tier</th>\n",
       "      <th>invite_tier</th>\n",
       "      <th>tier_change</th>\n",
       "      <th>fee_percent</th>\n",
       "      <th>invite_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>Commit</td>\n",
       "      <td>300</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>Market</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Participant</td>\n",
       "      <td>Bookrunner</td>\n",
       "      <td>Promoted</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>Decline</td>\n",
       "      <td>1200</td>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "      <td>Market</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "      <td>20.1</td>\n",
       "      <td>Bookrunner</td>\n",
       "      <td>Participant</td>\n",
       "      <td>Demoted</td>\n",
       "      <td>0.174783</td>\n",
       "      <td>0.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bank of America</td>\n",
       "      <td>Commit</td>\n",
       "      <td>900</td>\n",
       "      <td>130</td>\n",
       "      <td>3</td>\n",
       "      <td>Market</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>24.4</td>\n",
       "      <td>Bookrunner</td>\n",
       "      <td>Bookrunner</td>\n",
       "      <td>None</td>\n",
       "      <td>0.248980</td>\n",
       "      <td>0.144444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          investor   commit  deal_size  invite  rating int_rate  covenants  \\\n",
       "0    Goldman Sachs   Commit        300      40       2   Market          2   \n",
       "1    Deutsche Bank  Decline       1200     140       2   Market          2   \n",
       "2  Bank of America   Commit        900     130       3   Market          2   \n",
       "\n",
       "   total_fees  fee_share   prior_tier  invite_tier tier_change  fee_percent  \\\n",
       "0          30        0.0  Participant   Bookrunner    Promoted     0.000000   \n",
       "1         115       20.1   Bookrunner  Participant     Demoted     0.174783   \n",
       "2          98       24.4   Bookrunner   Bookrunner        None     0.248980   \n",
       "\n",
       "   invite_percent  \n",
       "0        0.133333  \n",
       "1        0.116667  \n",
       "2        0.144444  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_data = pd.read_csv(\"investor_data_2.csv\")\n",
    "inv_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_data = inv_data.drop([\"invite_tier\", \"fee_share\", \"invite\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7233, 21)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_inv_data = pd.get_dummies(inv_data)\n",
    "processed_inv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_inv_data = processed_inv_data.drop(\"commit_Commit\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = processed_inv_data.commit_Decline\n",
    "inputs = processed_inv_data.drop(\"commit_Decline\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing and splitting of data into target and inputs is complete. The next step is to split the data into a training and test set and build the model pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "split_list = train_test_split(inputs, target, test_size=0.2, random_state=1, stratify=processed_inv_data.commit_Decline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = split_list[0]\n",
    "input_test = split_list[1]\n",
    "target_train = split_list[2]\n",
    "target_test = split_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'l1' : make_pipeline(StandardScaler(), LogisticRegression(penalty='l1', random_state=1, solver='liblinear')),\n",
    "    'l2' : make_pipeline(StandardScaler(), LogisticRegression(penalty='l2', random_state=1, solver='liblinear')),\n",
    "    'rf' : make_pipeline(StandardScaler(), RandomForestClassifier(random_state=1)),\n",
    "    'gb' : make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_hyperparameters = {\n",
    "    'logisticregression__C' : [0.1, 1, 10]\n",
    "}\n",
    "l2_hyperparameters = {\n",
    "    'logisticregression__C' : [0.1, 1, 10]\n",
    "}\n",
    "rf_hyperparameters = {\n",
    "    'randomforestclassifier__n_estimators' : [100, 200], \n",
    "    'randomforestclassifier__max_features' : ['auto', 0.3, 0.6]\n",
    "}\n",
    "gb_hyperparameters = {\n",
    "    'gradientboostingclassifier__n_estimators' : [100, 200], \n",
    "    'gradientboostingclassifier__learning_rate' : [0.05, 0.1, 0.2],\n",
    "    'gradientboostingclassifier__max_depth' : [1,3,5]\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    'l1' : l1_hyperparameters,\n",
    "    'l2' : l2_hyperparameters,\n",
    "    'rf' : rf_hyperparameters,\n",
    "    'gb' : gb_hyperparameters,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create untrained models, train models and cross-validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method keys of dict object at 0x00000208DA0A5818>\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "for key in pipelines.keys():\n",
    "    models[key] = GridSearchCV(pipelines[key], hyperparameters[key], cv=5)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1  is trained and tuned\n",
      "l2  is trained and tuned\n",
      "rf  is trained and tuned\n",
      "gb  is trained and tuned\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    models[model].fit(input_train, target_train)\n",
    "    print(model, \" is trained and tuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC - for classification models, the area under the ROC curve is a more useful metric than the R^2. For imbalanced classes such as credit card fraud data where 99% of transactions are valid, the model can predict valid 100% of the time and have an R^2 of almost 1 despite misclassifying all the fraudulent transactions.\n",
    "\n",
    "For AUROC, a confusion matrix is necessary (True Negative, False Negative, False Positive, True Positive)\n",
    "\n",
    "AUROC is also called AUC ROC - area under the curve receiver operating characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1124   22]\n",
      " [  23  278]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = models['l1'].predict(input_test)\n",
    "print(confusion_matrix(target_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above indicates 1124 correctly predicted commits out of 1146 actual commits (1124+22).\n",
    "278 correctly predicted declines out of 301 actual declines (23+278).\n",
    "\n",
    "The model makes a trade-off between true positive rate and false positive rate. (Predicting Decline is the positive class). As the probability threshold increases, the true negative rate will increase; the model will identify more of the actual negative class. However, the false negative rate will also increase as more cases are predicted as negative.\n",
    "\n",
    "In the ideal situation of perfect separability (i.e. the true negative and true positive distributions do not overlap) the AUC is 1. A value of 0.5 is equivalent to a coin-flip\n",
    "\n",
    "the proability threshold depends on the goals of your models (whether it's more important to have specificity or sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " l1 \n",
      " AUROC =  0.9522\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve (target_test, pred) # default threshold 0.5\n",
    "print(\" l1 \\n\",\"AUROC = \", round(auc(fpr,tpr), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 \t AUROC =  0.9522\n",
      "l2 \t AUROC =  0.9518\n",
      "rf \t AUROC =  0.9616\n",
      "gb \t AUROC =  0.9683\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    pred  = models[model].predict(input_test)\n",
    "    fpr, tpr, thresholds = roc_curve(target_test, pred)\n",
    "    print(model, \"\\t AUROC = \", round(auc(fpr,tpr), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier has highest AUROC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
